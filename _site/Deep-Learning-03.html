<!DOCTYPE html>
<html>

<head>
	<!-- Meta -->
	<meta charset="UTF-8"/>
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
	<meta name="generator" content="Jekyll">

	<title>Deep Learning Concept 3: Learning Rate</title>
  <meta name="description" content="">

	<!-- CSS & fonts -->
	<link rel="stylesheet" href="/css/main.css">

	<!-- RSS -->
	<link href="/atom.xml" type="application/atom+xml" rel="alternate" title="ATOM Feed" />

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/png" href="img/favicon.png">

</head>


<body>
	<div id="wrap">
	  	
	  	<!-- Navigation -->
	  	<nav id="nav">
	<div id="nav-list">
		<a href="//">Home</a>

		<!-- Nav pages -->
	  
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
    
    <!-- Nav links -->
	  


	</div>
  
  <!-- Nav footer -->
	
	  <footer>
	
	<span>version 1.0.0</span>

</footer>
	

</nav>

    
    <!-- Icon menu -->
	  <a id="nav-menu">
	  	<div id="menu"></div>
	  </a>

      <!-- Header -->
      
        <header id="header" class="parent justify-spaceBetween">
  <div class="inner w100 relative">
    <span class="f-left">  
      <a href="//">
        <h1>
          <span>Xinyu Wu</span>
        </h1>
      </a>
    </span>
    <span id="nav-links" class="absolute right bottom">
      <!-- Nav pages -->
	    
	      
	    
	      
	    
	      
	    
	      
	    
	      
	    
	      
	    
      
      <!-- Nav links -->
	    


    </span>
  </div>
</header>




      

    <!-- Main content -->
	  <div id="container">
		  
		<main>

			<article id="post-page">
	<h2>Deep Learning Concept 3: Learning Rate</h2>		
	<time datetime="2018-09-05T00:00:00-04:00" class="by-line">05 Sep 2018</time>
	<div class="content">

		<h3 id="what-is-a-learning-rate">What is a learning rate?</h3>
<p>Learning rate is a hyper-parameter that controls how much we are adjusting the weights of our network with respect to the loss gradient</p>

<script type="math/tex; mode=display">new\_weight = existing\_weight - learning\_rate * gradient</script>

<h3 id="why-is-learning-rate-important">Why is learning rate important?</h3>
<p>Learning rate affects how quickly our model can converge to a local minima. Choosing a bad learning rate can results in network either fail to train or take much longer to converge.</p>

<h3 id="how-to-choose-the-best-learning-rate">How to choose the best learning rate?</h3>
<p>First we need to find the optimal learning rate range. The idea is that when learning rate is too low, the loss may also decrease very slow. When it gets into optimal range, the loss will drop quickly and when it gets out of optimal range, the loss will bounce around and even diverge from minima. In this way, we can know what is the optimal range.
Then after that, during training there are two way we can automatically adjust the learning rate:</p>
<ol>
  <li>learning rate annealing: start with relatively high learning rate and then gradually lowering the learning rate during training. The idea is that we can quickly get to the area of local minima and then find the local minima through small learning rate</li>
  <li>Cycle learning rate: initially proposed in this <a href="https://arxiv.org/abs/1506.01186">paper</a>. The author proposed a cyclical learning rate schdule which bounced between two values. It is a triangular update with either fixed cyclic decay or an exponential cyclic decay.</li>
</ol>


		
	</div>
</article>



	  </main>
		
		  <!-- Pagination links -->
      

	  </div>
	    
	    <!-- Footer -->
	    <footer><span></span></footer>


	    <!-- Script -->
      <script src="/js/main.js"></script>	
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


	</div>
</body>
</html>
